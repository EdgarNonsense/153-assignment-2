{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b23a036",
   "metadata": {},
   "source": [
    "# CSE 153 Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec57deb",
   "metadata": {},
   "source": [
    "## Task 2: Harmonization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4095543f",
   "metadata": {},
   "source": [
    "For this task, we will create a model that can generate harmonies and a backing track when provided a melody. (PROVIDE MORE DETAILS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce6626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt install fluidsynth\n",
    "# !git clone https://github.com/jthickstun/anticipation.git\n",
    "# !pip install ./anticipation\n",
    "# !pip install -r anticipation/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ca15de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import miditoolkit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anticipation\n",
    "import sys,time\n",
    "\n",
    "import midi2audio\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from anticipation import ops\n",
    "from anticipation.sample import generate\n",
    "from anticipation.tokenize import extract_instruments\n",
    "from anticipation.convert import events_to_midi,midi_to_events\n",
    "from anticipation.visuals import visualize\n",
    "from anticipation.config import *\n",
    "from anticipation.vocab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4bc34c",
   "metadata": {},
   "source": [
    "We will use the [POP909 dataset](https://arxiv.org/abs/2008.07142), which contains 909 piano arrangements of popular songs. Each song is broken into 3 midi files (MELODY, BRIDGE (for the harmonies), and PIANO (for the accompaniment)). The dataset comes with information about beat, chords, and key changes. We will be using their provided data preprocessing scripts to access these midi files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3daa0497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [038/038.mid]"
     ]
    }
   ],
   "source": [
    "# Pre-processing script by Ziyu Wang, Ke Chen, Junyan Jiang, Yiyi Zhang, Maoran Xu, \n",
    "# Shuqi Dai, Guxian Bin, and Gus Xia (POP909 team)\n",
    "\n",
    "def preprocess_midi(path):\n",
    "    midi_obj = miditoolkit.midi.parser.MidiFile(path)\n",
    "\n",
    "    melody = list(sorted(midi_obj.instruments[0].notes, key=lambda x: x.start))\n",
    "    # unsorted_melody = midi_obj.instruments[0].notes\n",
    "    # for n, note in enumerate(melody):\n",
    "    #     if note != unsorted_melody[n]:\n",
    "    #         print(note, unsorted_melody[n])\n",
    "    bridge = list(sorted(midi_obj.instruments[1].notes, key=lambda x: x.start))\n",
    "    piano = list(sorted(midi_obj.instruments[2].notes, key=lambda x: x.start))\n",
    "\n",
    "    data = {\n",
    "        \"melody\": melody,\n",
    "        \"ornamentation\": bridge,\n",
    "        \"harmony\": piano\n",
    "    }\n",
    "    \n",
    "    return data\n",
    "\n",
    "def preprocess_pop909(midi_root, save_dir):\n",
    "    save_py = []\n",
    "    midi_paths = [f\"{d}/{d}.mid\" for d in os.listdir(midi_root)]\n",
    "    i = 0\n",
    "    \n",
    "    for path in midi_paths:\n",
    "        print(' ', end='[{}]'.format(path), flush=True)\n",
    "        filename = midi_root + path\n",
    "        try:\n",
    "            data = preprocess_midi(filename)\n",
    "            # print(data[\"melody\"])\n",
    "        except KeyboardInterrupt:\n",
    "            print(' Abort')\n",
    "            return\n",
    "        except EOFError:\n",
    "            print('EOF Error')\n",
    "            return\n",
    "        break\n",
    "    #     save_py.append(data)\n",
    "    # save_py = np.array(save_py)\n",
    "    # print(save_py.size)\n",
    "    # np.save(\"pop909-event-token.npy\", save_py)\n",
    "            \n",
    "    \n",
    "# replace the folder with your POP909 data folder\n",
    "preprocess_pop909(\"POP909/\",\"midi_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb209f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_MODEL = 'stanford-crfm/music-small-800k'     # faster inference, worse sample quality\n",
    "\n",
    "# load an anticipatory music transformer\n",
    "model = AutoModelForCausalLM.from_pretrained(SMALL_MODEL).cuda()\n",
    "\n",
    "# a MIDI synthesizer\n",
    "fs = midi2audio.FluidSynth('/usr/share/sounds/sf2/FluidR3_GM.sf2')\n",
    "\n",
    "# the MIDI synthesis script\n",
    "def synthesize(fs, tokens):\n",
    "    mid = events_to_midi(tokens)\n",
    "    mid.save('tmp.mid')\n",
    "    fs.midi_to_audio('tmp.mid', 'tmp.wav')\n",
    "    return 'tmp.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in midi, synthesizes the first 30 seconds of the loaded MIDI file by clipping the loaded sequence of events.\n",
    "# The ops.clip function takes a list of events, a start_time, and an end_time, and returns the events in the interval \n",
    "# [start_time,end_time].\n",
    "\n",
    "events = midi_to_events('anticipation/examples/strawberry.mid') # EDIT FILE TO CORRECT MIDI\n",
    "Audio(synthesize(fs, ops.clip(events, 0, 30)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652da2f2",
   "metadata": {},
   "source": [
    "@inproceedings{pop909-ismir2020,\n",
    "    author = {Ziyu Wang* and Ke Chen* and Junyan Jiang and Yiyi Zhang and Maoran Xu and Shuqi Dai and Guxian Bin and Gus Xia},\n",
    "    title = {POP909: A Pop-song Dataset for Music Arrangement Generation},\n",
    "    booktitle = {Proceedings of 21st International Conference on Music Information Retrieval, {ISMIR}},\n",
    "    year = {2020}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
